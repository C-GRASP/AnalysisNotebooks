{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a154fcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import netCDF4\n",
    "import pandas as pd\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d2aacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-01-10 14:46:01--  https://www.ngdc.noaa.gov/thredds/fileServer/tiles/tiled_19as/ncei19_n49x00_w123x00_2019v2.nc\n",
      "Resolving www.ngdc.noaa.gov (www.ngdc.noaa.gov)... 140.172.190.1\n",
      "Connecting to www.ngdc.noaa.gov (www.ngdc.noaa.gov)|140.172.190.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 200\n",
      "Length: 147193634 (140M) [application/x-netcdf]\n",
      "Saving to: ‘ncei19_n49x00_w123x00_2019v2.nc’\n",
      "\n",
      "ncei19_n49x00_w123x 100%[===================>] 140.37M  2.63MB/s    in 57s     \n",
      "\n",
      "2022-01-10 14:46:58 (2.46 MB/s) - ‘ncei19_n49x00_w123x00_2019v2.nc’ saved [147193634/147193634]\n",
      "\n",
      "--2022-01-10 14:46:59--  https://www.ngdc.noaa.gov/thredds/fileServer/tiles/tiled_19as/ncei19_n49x00_w122x75_2019v2.nc\n",
      "Resolving www.ngdc.noaa.gov (www.ngdc.noaa.gov)... 140.172.190.1\n",
      "Connecting to www.ngdc.noaa.gov (www.ngdc.noaa.gov)|140.172.190.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 200\n",
      "Length: 157836487 (151M) [application/x-netcdf]\n",
      "Saving to: ‘ncei19_n49x00_w122x75_2019v2.nc’\n",
      "\n",
      "22x75_2019v2.nc      27%[====>               ]  41.13M  2.35MB/s    eta 45s    "
     ]
    }
   ],
   "source": [
    "#Download CUDEM Files\n",
    "\n",
    "\n",
    "os.chdir('/home/will/Desktop/USGS/CUDEM/Nc')\n",
    "#Extract link to file names from 1/9 arc second resolution server\n",
    "\n",
    "\n",
    "def get_url_paths(url, ext='', params={}):\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.ok:\n",
    "        response_text = response.text\n",
    "    else:\n",
    "        return response.raise_for_status()\n",
    "    soup = BeautifulSoup(response_text, 'html.parser')\n",
    "    parent = [url + node.get('href') for node in soup.find_all('a') if node.get('href').endswith(ext)]\n",
    "    return parent\n",
    "\n",
    "url = 'https://www.ngdc.noaa.gov/thredds/catalog/tiles/tiled_19as/catalog.html'\n",
    "ext = 'nc'\n",
    "result = get_url_paths(url, ext)\n",
    "\n",
    "#Make links into df\n",
    "link_df = pd.DataFrame(columns = ['link'])\n",
    "link_df['link']=result\n",
    "\n",
    "#split link field by '/' delimiter to get file name\n",
    "\n",
    "link_df['filename']=link_df['link'].str.split('/', expand=True)[9]\n",
    "\n",
    "#download iterating through each file name\n",
    "\n",
    "base_url='https://www.ngdc.noaa.gov/thredds/fileServer/tiles/tiled_19as/' #base url for download\n",
    "i=0\n",
    "for i in range(0,len(link_df)):\n",
    "    file_name=link_df['filename'][i]\n",
    "    dwnld_link=base_url+file_name\n",
    "    !wget {dwnld_link}\n",
    "    i=i+1\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8f9bfa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert downloaded nc files to csv\n",
    "csv_folder='/home/will/Desktop/USGS/CUDEM/'#enter path for csv folder\n",
    "\n",
    "for filename in os.listdir(os.getcwd()):\n",
    "    if filename.endswith(\".nc\"):\n",
    "        nc = netCDF4.Dataset(os.path.join(os.getcwd(), filename), mode='r')\n",
    "        file_name_no_ext=os. path. splitext(filename)[0]\n",
    "        out_name=csv_folder+file_name_no_ext+'.csv'\n",
    "        df = pd.DataFrame(columns = ['latitude','longitude','depth'])\n",
    "        df['latitude']=nc.variables['lat'][:]\n",
    "        df['longitude']= nc.variables['lon'][:]\n",
    "        df['depth']=nc.variables['Band1'][:]\n",
    "        df['crs']=nc.variables['crs'][:]\n",
    "        df.to_csv(out_name)\n",
    "        a=a+1        \n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "01073f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/anaconda3/envs/USGS/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3357: DtypeWarning: Columns (1,2,6,7,10,11,12,13,15,21,23,26,27,28) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "#merge csv's into one df\n",
    "\n",
    "\n",
    "os.chdir(csv_folder)\n",
    "\n",
    "#create list of files in folder\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "\n",
    "#combine all files in the list\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
    "\n",
    "cudem_df=combined_csv \n",
    "\n",
    "#round lat lon to 4th decimal place\n",
    "cudem_df['latitude']=cudem_df['latitude'].round(decimals=3)\n",
    "cudem_df['longitude']=cudem_df['longitude'].round(decimals=3)\n",
    "\n",
    "#create lat lon combined column\n",
    "cudem_df['latlon']= cudem_df['latitude'].map(str)+','+cudem_df['longitude'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d83f0450",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/anaconda3/envs/USGS/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (1,2,6,7,10,11,12,13,15,21,23,26,27,28) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "#call in sample dataset\n",
    "\n",
    "# from https://stackoverflow.com/questions/38511444/python-download-files-from-google-drive-using-url\n",
    "\n",
    "def download_file_from_google_drive(id, destination):\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = { 'id' : id, 'confirm' : token }\n",
    "        response = session.get(URL, params = params, stream = True)\n",
    "\n",
    "    save_response_content(response, destination)    \n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "\n",
    "    return None\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    \"\"\"\n",
    "    response = filename for input\n",
    "    destination = filename for output\n",
    "    \"\"\"    \n",
    "    CHUNK_SIZE = 32768\n",
    "\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in response.iter_content(CHUNK_SIZE):\n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)\n",
    "\n",
    "\n",
    "DATASET_ID = '1G9fuC_TjtwTr3JWA85gW7228_Ffxsw0G'\n",
    "\n",
    "\n",
    "destination = csv_folder+'sample_data.csv'\n",
    "download_file_from_google_drive(DATASET_ID, destination)\n",
    "sample_df= pd.read_csv(destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "085b5df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#round sample lat lon to 4th decimal place\n",
    "sample_df['latitude']=sample_df['latitude'].round(decimals=3)\n",
    "sample_df['longitude']=sample_df['longitude'].round(decimals=3)\n",
    "\n",
    "\n",
    "#create lat lon combined column\n",
    "sample_df['latlon']= sample_df['latitude'].map(str)+','+sample_df['longitude'].map(str)\n",
    "\n",
    "#merge dataframes on latlon column\n",
    "\n",
    "merged_df=pd.merge(sample_df,cudem_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
