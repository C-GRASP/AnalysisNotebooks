{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Compute  Sample Cohesive, Sand, and Coarse Percent Fraction**\n",
    "\n",
    "## This notebook serves as a guide of how to calculate sample cohesive, sand, and coarse percentage for each sample within a sample dataset. This function works on a dataset with with measured distribution percentiles (e.g. d10,d50,d90, etc.). To calculate distributions see the sample_compute_percentile repo\n",
    "\n",
    "* To do so, the user enters a dataset where the values of percentile distributions are provided (e.g., d10, d50, d90).\n",
    "    \n",
    "    \n",
    "*  The user will then enter in the distributions that were provided to them (e.g., d10, d50, d90).\n",
    "\n",
    "* Then the notebook will then run an iterative function that interpolates the cumulative distribution of each sample, and finds the percentage of samples that are below and above the minimum and wentworth classification of sand sediment grain size in millimeters respectively.\n",
    "\n",
    "\n",
    "## <font color=grey> *This notebook's output adds threee new field to the input sample data dataframe for each sample that specifies the percent cohesives,sands, and coarse of the sample composition. To calculate interpolation error or to translate sample data from phi to mm units, see the other notebooks within this repository*<font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run these two cells  to get everything set up. The second cell is only necessary in this example to pull the example data from Google Drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.interpolate import interp1d\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://stackoverflow.com/questions/38511444/python-download-files-from-google-drive-using-url\n",
    "\n",
    "def download_file_from_google_drive(id, destination):\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = { 'id' : id, 'confirm' : token }\n",
    "        response = session.get(URL, params = params, stream = True)\n",
    "\n",
    "    save_response_content(response, destination)    \n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "\n",
    "    return None\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    \"\"\"\n",
    "    response = filename for input\n",
    "    destination = filename for output\n",
    "    \"\"\"    \n",
    "    CHUNK_SIZE = 32768\n",
    "\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in response.iter_content(CHUNK_SIZE):\n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)\n",
    "\n",
    "\n",
    "DATASET_ID = '1p_x1boL12i-Yt1Eou845vf4CbaOEEOLr'\n",
    "\n",
    "\n",
    "destination = '../data.csv'\n",
    "download_file_from_google_drive(DATASET_ID, destination)\n",
    "df= pd.read_csv(destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this cell with your own data instead of the example data by entering the filepath of a desired file. If you want to use the example data, skip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter variable here\"\n",
    "filepath='user/your_folder/your_file.csv'\n",
    "\n",
    "\n",
    "df= pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this cell specifiy the names of the given distributions within the sample data (i.e. d10, d50, d90) within the \"distributions\" variable. In our example data from SandSnap, we are provided with d10, d16, d25, d50, d65, d75, d84, d90\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "distributions=str('d10,d16,d25,d50,d65,d75,d84,d90')\n",
    "\n",
    "\n",
    "\n",
    "#extract distribution values and distribution names that were provided with the source dataset (e.g, 'd50' and .5)\n",
    "given_dist_vals=[]\n",
    "given_dist_names=[]\n",
    "\n",
    "for i in range(0,len((distributions).split(',',))):\n",
    "    a=(distributions).split(',',)[i]\n",
    "    b=a.split('d')[1]\n",
    "    val=int(b)/100\n",
    "    given_dist_names.append(a)\n",
    "    given_dist_vals.append(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this cell to calculate percent sand. It will first iterate through each sample and calculate the percent sand via cumulative interpolation. Then it will take the found cumulative percentile for the minimum and maximum wentworth sand grain size (mm) then turn it into a percent fraction and assign the appropriate percent fractions for cohesive, coarse, and sand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(0,(len(df))):#repeats for each row, aka sample \n",
    "    #create an array of distribution grain sizes for each sample \n",
    "    grain_size_bins=[]\n",
    "    #This collects the values from the distributions\n",
    "    for ia in range(0,len((distributions).split(',',))):\n",
    "        bin_size=df[given_dist_names[ia]].iloc[i] \n",
    "        grain_size_bins.append(bin_size)\n",
    "        grain_size_frequencies=given_dist_vals\n",
    "\n",
    "        #This interpolates the value using the gathered \"original\" distributions from above\n",
    "    p=scipy.interpolate.interp1d(grain_size_bins,grain_size_frequencies, bounds_error=False, fill_value='extrapolate')\n",
    "\n",
    "    #This finds the cumulative percentile for the minimum wentworth sand grain size (mm) and compiles it into a column\n",
    "    df.loc[i,[\"%Sand\"]]=scipy.interpolate.interp1d(grain_size_bins,grain_size_frequencies, bounds_error=False, fill_value='extrapolate')(2.0)\n",
    "    df.loc[i,[\"%Cohesive\"]]=scipy.interpolate.interp1d(grain_size_bins,grain_size_frequencies, bounds_error=False, fill_value='extrapolate')(.063)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#If Maximum cohesive grainsize is under 0th percentile, then 0% is cohesive\n",
    "df['%Cohesive']=np.where(df['%Cohesive']<0,0,df['%Cohesive'])\n",
    "#If Maximum cohesive grainsize is over 100th percentile, this sets it as 100% percent cohesive\n",
    "df['%Cohesive']=np.where(df['%Cohesive']>1,1,df['%Cohesive'])\n",
    "#If sand percentile is under 0%, this sets it to zero\n",
    "df[\"%Sand\"]=np.where(df[\"%Sand\"]<0,0,df[\"%Sand\"])\n",
    "#If percentile %sand is over 100%, this sets it to 100% sand\n",
    "df[\"%Sand\"]=np.where(df[\"%Sand\"]>1,1,df[\"%Sand\"])\n",
    "#This calculates the final sand fraction. If cohesive is 100th percentile, then sand is 0%\n",
    "df[\"%Sand\"]=df[\"%Sand\"]-df['%Cohesive']\n",
    "\n",
    "#Remaining percentile is gravel\n",
    "df['%Coarse']=1-df[\"%Sand\"]-df['%Cohesive']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this cell if you want to export data back to csv. In the \"out_path\" variable specify where you want the file to be saved and how you want it to be named.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter desired outpath\n",
    "out_path='user/your_folder/your_converted_file.csv'\n",
    "\n",
    "pd.write_csv(df, outpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
