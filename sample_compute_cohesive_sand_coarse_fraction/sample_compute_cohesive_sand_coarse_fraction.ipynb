{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"font-size: 1em; padding: 0; margin: 0;\">\n",
    "\n",
    "<tr style=\"vertical-align: top; padding: 0; margin: 0;background-color: #ffffff\">\n",
    "        <td style=\"vertical-align: top; padding: 0; margin: 0; padding-right: 15px;\">\n",
    "    <p style=\"background: #182AEB; color:#ffffff; text-align:justify; padding: 10px 25px;\">\n",
    "        <strong style=\"font-size: 1.0em;\"><span style=\"font-size: 1.2em;\"><span style=\"color: #ffffff;\">The Coastal Grain Size Portal (C-GRASP) dataset <br/><em>Will Speiser, Daniel Buscombe, and Evan Goldstein</em></strong><br/><br/>\n",
    "        <strong>> Categorize Samples by percent sand, percent mud, and percent coarse </strong><br/>\n",
    "    </p>                       \n",
    "                \n",
    "<p style=\"border: 1px solid #ff5733; border-left: 15px solid #ff5733; padding: 10px; text-align:justify;\">\n",
    "    <strong style=\"color: #ff5733\">The purpose of this notebook</strong>  \n",
    "    <br/><font color=grey>  This notebook serves as a guide of how to calculate percent cohesive, percent sand, and percent coarse sediment for each sample within a chosen sample dataset.<font><br/>\n",
    "   <br/><font color=grey> This notebook calls selected data from the CGRASP zenodo repository and runs an iterative function that interpolates the cumulative distribution of each sample, and finds the percentage of samples that are below and above the minimum and wentworth classification of sand sediment grain size in millimeters respectively.<font><br/>\n",
    "   <br/><font color=grey> The code will compute and add three new fields to the input sample data dataframe for each sample that specifies the percent cohesives,sands, and coarse of the sample composition. To calculate interpolation error or to translate sample data from phi to mm units, see the other notebooks within this repository.<font><br/>   \n",
    "   <br/><font color=grey> The output of the notebook is a csv with the selected CGRASP dataset and the above three new fields <font><br/>   \n",
    "    </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "# from scipy.interpolate import interp1d\n",
    "import ipywidgets\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset collection widget\n",
    "zen=ipywidgets.Select(\n",
    "    options=['Entire Dataset', 'Estimated Onshore Data', 'Verified Onshore Data', 'Verified Onshore Post 2012 Data'],\n",
    "    value='Entire Dataset',\n",
    "    # rows=10,\n",
    "    description='Dataset:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "display(zen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download chosen dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://zenodo.org/record/6099266/files/' \n",
    "if zen.value=='Entire Dataset':\n",
    "    filename='dataset_10kmcoast.csv'\n",
    "if zen.value=='Estimated Onshore Data':\n",
    "    filename='Data_EstimatedOnshore.csv'\n",
    "if zen.value=='Verified Onshore Data':\n",
    "    filename='Data_VerifiedOnshore.csv'\n",
    "if zen.value=='Verified Onshore Post 2012 Data':\n",
    "    filename='Data_Post2012_VerifiedOnshore.csv'\n",
    "    \n",
    "print(\"Downloading {}\".format(url+filename))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "url=(url+filename)\n",
    "print('Retrieving Data, Please Wait')\n",
    "#retrieve data\n",
    "df=pd.read_csv(url)\n",
    "print('Sediment Data Retrieved!') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify percentiles\n",
    "\n",
    "In this cell specifiy the names of the given distributions within the sample data (i.e. d10, d50, d90) within the `percentiles` variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles=str('d10,d16,d25,d50,d65,d75,d84,d90')\n",
    "\n",
    "#extract percentile values and percentile names that were provided with the source dataset (e.g, 'd50' and .5)\n",
    "given_dist_vals=[]\n",
    "given_dist_names=[]\n",
    "\n",
    "for i in range(0,len((percentiles).split(',',))):\n",
    "    a=(percentiles).split(',',)[i]\n",
    "    b=a.split('d')[1]\n",
    "    val=int(b)/100\n",
    "    given_dist_names.append(a)\n",
    "    given_dist_vals.append(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate percent sand and percent cohesive\n",
    "\n",
    "Run this cell to calculate percent sand and percent cohesive. \n",
    "\n",
    "It will first iterate through each sample and calculate the percent sand via cumulative interpolation. Then it will take the found cumulative percentile for the minimum and maximum wentworth sand grain size (mm) then turn it into a percent fraction and assign the appropriate percent fractions for cohesive, coarse, and sand.\n",
    "\n",
    "This may take a long time on the full dataset - please consult the waitbar at the bottom of the cell to view progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(0,(len(df)))):#repeats for each row, aka sample \n",
    "    #create an array of distribution grain sizes for each sample \n",
    "    grain_size_bins=[]\n",
    "    #This collects the values from the distributions\n",
    "    for ia in range(0,len((percentiles).split(',',))):\n",
    "        bin_size=df[given_dist_names[ia]].iloc[i] \n",
    "        grain_size_bins.append(bin_size)\n",
    "        grain_size_frequencies=given_dist_vals\n",
    "        \n",
    "    grain_size_frequencies = np.array(grain_size_frequencies)\n",
    "    grain_size_bins = np.array(grain_size_bins)\n",
    "\n",
    "    # find grain size bins in the sand range\n",
    "    sand_bin_freqs = grain_size_frequencies[(grain_size_bins<=2.0) & (grain_size_bins>.063)]\n",
    "    \n",
    "    # if not nan\n",
    "    if len(sand_bin_freqs)>0:\n",
    "\n",
    "        # get the range of frequencies covered by sand fraction\n",
    "        prop_sand = sand_bin_freqs.max() - sand_bin_freqs.min()\n",
    "\n",
    "        # if that range is the same as the full range, assume 100% sand\n",
    "        if prop_sand==(np.max(grain_size_frequencies) - np.min(grain_size_frequencies)):\n",
    "            prop_sand = 1.0\n",
    "    else:\n",
    "        prop_sand = np.nan\n",
    "        \n",
    "    df.loc[i,[\"%Sand\"]] = 100*prop_sand\n",
    "    \n",
    "    # find grain size bins in the cohesive range\n",
    "    cohesive_bin_freqs = grain_size_frequencies[(grain_size_bins<=.063) & (grain_size_bins>0)]\n",
    "    \n",
    "    # if not nan\n",
    "    if len(cohesive_bin_freqs)>0:\n",
    "\n",
    "        # get the range of frequencies covered by sand fraction\n",
    "        prop_cohesive = cohesive_bin_freqs.max() - cohesive_bin_freqs.min()\n",
    "\n",
    "        # if that range is the same as the full range, assume 100% sand\n",
    "        if prop_cohesive==(np.max(grain_size_frequencies) - np.min(grain_size_frequencies)):\n",
    "            prop_cohesive = 1.0\n",
    "    else:\n",
    "        prop_cohesive = np.nan\n",
    "        \n",
    "    df.loc[i,[\"%Cohesive\"]] = 100*prop_cohesive    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute percentage mud and silt (\"cohesive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute percentage gravel (\"coarse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remaining percentile is gravel\n",
    "df['%Coarse']=100-(df[\"%Sand\"]+df['%Cohesive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a quick plot to view distribution of 'percent sand'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['%Sand'][np.isfinite(df['%Sand'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a quick plot to view distribution of 'percent coarse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['%Coarse'][np.isfinite(df['%Coarse'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a quick plot to view distribution of 'percent cohesive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['%Cohesive'][np.isfinite(df['%Cohesive'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, define a csv file name for the output dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csvfile='../data_plus_fractions.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write the data to that csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_csvfile) #convert data to CSV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
