{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c8ab114",
   "metadata": {},
   "source": [
    "<table style=\"font-size: 1em; padding: 0; margin: 0;\">\n",
    "\n",
    "<tr style=\"vertical-align: top; padding: 0; margin: 0;background-color: #ffffff\">\n",
    "        <td style=\"vertical-align: top; padding: 0; margin: 0; padding-right: 15px;\">\n",
    "    <p style=\"background: #182AEB; color:#ffffff; text-align:justify; padding: 10px 25px;\">\n",
    "        <strong style=\"font-size: 1.0em;\"><span style=\"font-size: 1.2em;\"><span style=\"color: #ffffff;\">The Coastal Grain Size Portal (C-GRASP) dataset <br/><em>Will Speiser, Daniel Buscombe, Evan Goldstein</em></strong><br/><br/>\n",
    "        <strong>> Assign Depth to Sample </strong><br/>\n",
    "    </p>                       \n",
    "        \n",
    "<p style=\"border: 1px solid #ff5733; border-left: 15px solid #ff5733; padding: 10px; text-align:justify;\">\n",
    "    <strong style=\"color: #ff5733\">The purpose of this notebook</strong>  \n",
    "    <br/><font color=grey> This notebook will output a dataframe containing all of the data from a chosen C-GRASP dataset with a new field containing a depth estimation from NOAA CUDEM topobathy dataset. As both C-Grasp and CUDEM file sizes vary completion of this task will vary with internet connectivity.<font><br/>\n",
    "    <br/><font color=grey> This notebook provides simple code that estimates a sample's depth based on CUDEM files.<font><br/>    \n",
    "    <br/><font color=grey> To do so, a user can choose a C-GRASP and CUDEM dataset of choice.  <font><br/>\n",
    "    <br/><font color=grey> The notebook then downloads all of the CUDEM files of chosen resolution to the user's computer. Please choose resolution carefully as this process take a long time depending on which resolution the user chooses.<font><br/>\n",
    "    <br/><font color=grey> Then the notebook converts each CUDEM cell value to a csv containing the CUDEM file's depth value and location for each cell. After, these csv's are combined into one dataframe<font><br/>\n",
    "    <br/><font color=grey> After the CUDEM data conversion, the chosen C-GRASP dataset is downloaded and converted to a dataframe.<font><br/>\n",
    "        <br/><font color=grey> Finally the two datasets are converted to GeoPandasData frames and are joined by proximity, assigning each downloaded CGRASP sample a depth from the nearest CUDEM value. This data is then downloaded as a csv to the user's system. <font><br/>\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98826cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import netCDF4\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import ipywidgets\n",
    "import geopandas as gpd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f5e5b5",
   "metadata": {},
   "source": [
    "## Select a dataset. Choose your CUDEM dataset mindfully as the higher resolution files can take significantly longer to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c020f28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Dataset collection widget\n",
    "zen=ipywidgets.Select(\n",
    "    options=['Entire Dataset', 'Estimated Onshore Data', 'Verified Onshore Data', 'Verified Onshore Post 2012 Data'],\n",
    "    value='Entire Dataset',\n",
    "    # rows=10,\n",
    "    description='Dataset:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "display(zen)\n",
    "\n",
    "#Dataset collection widget\n",
    "resc=ipywidgets.Select(\n",
    "    options=['3 arc-second', '1 arc-second', '1/3 arc-second', '1/9 arc-second'],\n",
    "    value='3 arc-second',\n",
    "    # rows=10,\n",
    "    description='CUDEM:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "display(resc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f7ce97",
   "metadata": {},
   "source": [
    "## Here, we download the chosen Cudem Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6601b39b",
   "metadata": {},
   "source": [
    "First we grab the appropriate abreviation to put in the download url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6ce748",
   "metadata": {},
   "outputs": [],
   "source": [
    "if resc.value == '3 arc-second':\n",
    "    res='3as'\n",
    "if resc.value == '1 arc-second':\n",
    "    res='1as'\n",
    "if resc.value == '1/3 arc-second':\n",
    "    res='13as'\n",
    "if resc.value == '1/9 arc-second':\n",
    "    res='19as'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c209c5",
   "metadata": {},
   "source": [
    "#### Then we download your data to file. Depending on the resolution you pick and your download speeds this can take from minutes to nearly a day, so proceed with caution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b0e0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download CUDEM Files\n",
    "\n",
    "os.chdir('.../')\n",
    "#Extract link to file names from 1/9 arc second resolution server\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_url_paths(url, ext='', params={}):\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.ok:\n",
    "        response_text = response.text\n",
    "    else:\n",
    "        return response.raise_for_status()\n",
    "    soup = BeautifulSoup(response_text, 'html.parser')\n",
    "    parent = [url + node.get('href') for node in soup.find_all('a') if node.get('href').endswith(ext)]\n",
    "    return parent\n",
    "\n",
    "url = 'https://www.ngdc.noaa.gov/thredds/catalog/tiles/tiled_'+res+'/catalog.html'\n",
    "ext = 'nc'\n",
    "result = get_url_paths(url, ext)\n",
    "\n",
    "#Make links into df\n",
    "link_df = pd.DataFrame(columns = ['link'])\n",
    "link_df['link']=result\n",
    "\n",
    "#split link field by '/' delimiter to get file name\n",
    "\n",
    "link_df['filename']=link_df['link'].str.split('/', expand=True)[9]\n",
    "\n",
    "#download iterating through each file name\n",
    "\n",
    "base_url='https://www.ngdc.noaa.gov/thredds/fileServer/tiles/tiled_'+res+'//' #base url for download\n",
    "i=0\n",
    "for i in range(0,len(link_df)):\n",
    "    file_name=link_df['filename'][i]\n",
    "    dwnld_link=base_url+file_name\n",
    "    !wget {dwnld_link}\n",
    "    i=i+1\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4e4fda",
   "metadata": {},
   "source": [
    "### This cell converts all of the downloaded cudem nc's into .csv files with fields for latitude, longitude, depth, and crs.  This may take a bit, especially with larger files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bc84f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert downloaded nc files to csv\n",
    "csv_folder='../'#this is where your csv's will download\n",
    "\n",
    "\n",
    "#for filename in os.listdir(os.chdir('.../Nc')):\n",
    "for filename in os.listdir('/home/will/Desktop/USGS/CUDEM/Nc'):\n",
    "    if filename.endswith(\".nc\"): #\n",
    "        try:\n",
    "            nc = netCDF4.Dataset(os.path.join(os.getcwd(), filename), mode='r')\n",
    "            #establish naming components\n",
    "            file_name_no_ext=os. path. splitext(filename)[0] \n",
    "            out_name=csv_folder+file_name_no_ext+'.csv'\n",
    "            #create a pandas dataframe\n",
    "            df = pd.DataFrame(columns = ['latitude','longitude','depth'])\n",
    "            #assign values from nc files to dataframe\n",
    "            df['latitude']=nc.variables['lat'][:]\n",
    "            df['longitude']= nc.variables['lon'][:]\n",
    "            df['depth']=nc.variables['Band1'][:]\n",
    "            df['crs']=nc.variables['crs'][:]\n",
    "            df.to_csv(out_name)\n",
    "        except:\n",
    "            pass\n",
    "    else:\n",
    "        continue\n",
    "print('Data Conversion Sucessful!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087d4281",
   "metadata": {},
   "source": [
    "This cell converts combines all of the  csv's into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12002ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge csv's into one df\n",
    "os.chdir(csv_folder)\n",
    "\n",
    "#create list of files in folder\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "#combine all files in the list\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
    "\n",
    "cudem_df=combined_csv "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b6e404",
   "metadata": {},
   "source": [
    "Lets look at that dataframe and see how it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34332bdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cudem_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb025ca",
   "metadata": {},
   "source": [
    "#### Download the sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8002b4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://zenodo.org/record/5874231/files/' \n",
    "if zen.value=='Entire Dataset':\n",
    "    filename='dataset_10kmcoast.csv'\n",
    "if zen.value=='Estimated Onshore Data':\n",
    "    filename='Data_EstimatedOnshore.csv'\n",
    "if zen.value=='Verified Onshore Data':\n",
    "    filename='Data_VerifiedOnshore.csv'\n",
    "if zen.value=='Verified Onshore Post 2012 Data':\n",
    "    filename='Data_Post2012_VerifiedOnshore.csv'\n",
    "print(\"Downloading {}\".format(url+filename))   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc940db",
   "metadata": {},
   "source": [
    "The next cell will download the CGRASP dataset and read it in as a pandas dataframe with variable name `sample_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2becaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=(url+filename)\n",
    "print('Retrieving Data, Please Wait')\n",
    "#retrieve data\n",
    "sample_df=pd.read_csv(url)\n",
    "print('Sediment Data Retrieved!') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0682214a",
   "metadata": {},
   "source": [
    "Let's take a quick look at the top of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f9b189",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de9b49b",
   "metadata": {},
   "source": [
    "## Now lets make use of both datasets to assign depths from CUDEM to C-Grasp Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb4b1b7",
   "metadata": {},
   "source": [
    "Turn the sample and CUDEM datasets in to GeoDataFrames (spatial data) and project them to the same CRS(EPSG:4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b29b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the CUDEM dataframe\n",
    "\n",
    "cudem_gdf = gpd.GeoDataFrame(\n",
    "    cudem_df, geometry=gpd.points_from_xy(cudem_df.longitude, cudem_df.latitude))\n",
    "\n",
    "cudem_gdf=cudem_gdf.set_crs('EPSG:4326')\n",
    "\n",
    "#convert the C-GRASP dataframe\n",
    "sample_gdf = gpd.GeoDataFrame(\n",
    "    sample_df, geometry=gpd.points_from_xy(sample_df.longitude, sample_df.latitude))\n",
    "\n",
    "sample_gdf=sample_gdf.set_crs('EPSG:4326')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ded7165",
   "metadata": {},
   "source": [
    "This cell will use the package Geopandas' sjoin_nearest function to join together the sediment samples with its nearest CUDEM depth measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8775ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = sample_gdf.sjoin_nearest(cudem_gdf, how=\"left\")\n",
    "\n",
    "df=pd.DataFrame(joined)\n",
    "\n",
    "#drop geometry column \n",
    "df=df.drop(columns=['geometry'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683aad76",
   "metadata": {},
   "source": [
    "Let's take a look to see how that worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca72eedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77eae94b",
   "metadata": {},
   "source": [
    "### Write to file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d696e2cb",
   "metadata": {},
   "source": [
    "Finally, define a csv file name for the output dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a516b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csvfile='../data_CudemDepths.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29a9af4",
   "metadata": {},
   "source": [
    "write the data to that csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3281231",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_csvfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
